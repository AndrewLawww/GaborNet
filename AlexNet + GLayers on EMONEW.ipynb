{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import rand, randn\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.modules.conv import _ConvNd\n",
    "from torch.nn.modules.utils import _pair\n",
    "\n",
    "class MyGabor(_ConvNd):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, bias=False):\n",
    "        kernel_size = _pair(kernel_size)\n",
    "        stride = _pair(stride)\n",
    "        padding = _pair(padding)\n",
    "        dilation = _pair(dilation)\n",
    "        \n",
    "        super(MyGabor, self).__init__(in_channels, out_channels, kernel_size, stride, padding, dilation,False, _pair(0), groups, bias)\n",
    "        \n",
    "        # TODO: подумать над инициализацией параметров\n",
    "        self.sigma_x = nn.Parameter(kernel_size[0]/3*torch.rand(in_channels,out_channels))\n",
    "        self.sigma_y = nn.Parameter(kernel_size[0]/3*torch.rand(in_channels,out_channels))\n",
    "        self.freq = nn.Parameter(kernel_size[0]*torch.rand(in_channels,out_channels))\n",
    "        self.theta = nn.Parameter(3.14*torch.rand(in_channels,out_channels))\n",
    "        self.psi = nn.Parameter(3.14*torch.rand(in_channels,out_channels))\n",
    "        #self.evaluate = False\n",
    "    \n",
    "    #def eval(self):\n",
    "        #self.evaluate = True\n",
    "        \n",
    "    #def train(self):\n",
    "        #self.evaluate = False\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        '''if self.evaluate == True:\n",
    "            return F.conv2d(input, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)'''\n",
    "        \n",
    "        x0 = torch.ceil(torch.Tensor([self.kernel_size[0]/2]))[0]\n",
    "        y0 = torch.ceil(torch.Tensor([self.kernel_size[1]/2]))[0]\n",
    "        y, x = torch.meshgrid([torch.arange(-y0+1,y0), torch.arange(-x0+1,x0)])\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        weight = torch.empty(self.weight.shape, requires_grad=False).to(device)\n",
    "        for i in range(self.in_channels):\n",
    "            for j in range(self.out_channels):\n",
    "                sigma_x = self.sigma_x[i,j].expand_as(y)\n",
    "                sigma_y = self.sigma_y[i,j].expand_as(y)\n",
    "                freq = self.freq[i,j].expand_as(y)\n",
    "                theta = self.theta[i,j].expand_as(y)\n",
    "                psi = self.psi[i,j].expand_as(y)\n",
    "                \n",
    "                rotx = x * torch.cos(theta) + y * torch.sin(theta)\n",
    "                roty = -x * torch.sin(theta) + y * torch.cos(theta) \n",
    "                g = torch.zeros(y.shape)\n",
    "                g = torch.exp(-0.5 * (rotx ** 2 / (sigma_x + 1e-3) ** 2 + roty ** 2 / (sigma_y + 1e-3) ** 2))\n",
    "                g = g * torch.cos(2 * 3.14 * freq * rotx + psi) #/ (2*3.14*sigma_x*sigma_y)\n",
    "                weight[j,i] = g\n",
    "                self.weight.data[j,i] = g    \n",
    "        return F.conv2d(input, weight, self.bias, self.stride, self.padding, self.dilation, self.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from random import choice\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class DatasetLoader():\n",
    "    def __init__(self, source_path = 'D:\\!EMONEW_cropped', classes = 7, train = 0.66):\n",
    "        self.source_path = os.path.normpath(source_path)\n",
    "        self.data = []\n",
    "        self.test_data = []\n",
    "        self.num_classes = classes\n",
    "        self.train = train\n",
    "        \n",
    "        for path in os.listdir(path=source_path):\n",
    "            source_path = os.path.join(self.source_path, path)\n",
    "            if os.path.isdir(source_path):\n",
    "                classes = classes - 1\n",
    "                target = [0]*self.num_classes\n",
    "                target[classes] = 1\n",
    "                self._list_to_jpeg(source_path, target)\n",
    "            \n",
    "    def _list_to_jpeg(self, path, target):\n",
    "        for i in os.walk(path):\n",
    "            for j in i[2]:\n",
    "                if '.jpg' in j or '.png' in j:\n",
    "                    if np.random.rand() <= self.train:\n",
    "                        self.data.append([[os.path.join(i[0], j)], target])\n",
    "                    else:\n",
    "                        self.test_data.append([[os.path.join(i[0], j)], target])\n",
    "    def get_batch(self, len_batch, train = True):\n",
    "        batch_data = []\n",
    "        batch_target = []\n",
    "        for i in range(len_batch):\n",
    "            if train == True:\n",
    "                d, t = choice(self.data)\n",
    "            else:\n",
    "                d, t = choice(self.test_data)\n",
    "            batch_target.append(t)\n",
    "            batch_data.append(np.asarray(Image.open(d[0])).transpose(2,0,1))\n",
    "        return np.array(batch_data), np.array(batch_target)\n",
    "    \n",
    "    def lenght(self, train = True):\n",
    "        if train == True:\n",
    "            return len(self.data)\n",
    "        else:\n",
    "            return len(self.test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.g1 = MyGabor(3, 96, kernel_size=(17,17))\n",
    "        self.bn1 = nn.BatchNorm2d(96)\n",
    "        self.c1 = nn.Conv2d(96, 128, kernel_size=(3,3))\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.c2 = nn.Conv2d(128, 128, kernel_size=(3,3))\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.c3 = nn.Conv2d(128, 192, kernel_size=(3,3))\n",
    "        \n",
    "        self.fc1 = nn.Linear(192*14*13, 32)\n",
    "        self.fc2 = nn.Linear(32, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x/255\n",
    "        x = F.max_pool2d(F.relu(self.bn1(self.g1(x))), kernel_size=4)\n",
    "        x = F.max_pool2d(F.relu(F.dropout2d(self.bn2(self.c1(x)), inplace=True)), kernel_size=2)\n",
    "        x = F.max_pool2d(F.relu(F.dropout2d(self.bn3(self.c2(x)), inplace=True)), kernel_size=2)\n",
    "        x = F.relu(self.c3(x))\n",
    "        x = x.view(-1, 192*14*13)\n",
    "        x = F.relu(F.dropout(self.fc1(x), inplace=True))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Net(\n",
      "  (g1): MyGabor(3, 96, kernel_size=(17, 17), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (c1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (c2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (c3): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=34944, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "net = Net().to(device)\n",
    "print(net)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0, weight_decay = 0.9999)\n",
    "EMONEW = DatasetLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "for epoch in range(250):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i in range(int(EMONEW.lenght()/BATCH_SIZE)):\n",
    "        net.train()\n",
    "        # get the inputs\n",
    "        inputs, labels = EMONEW.get_batch(BATCH_SIZE)\n",
    "        inputs = torch.Tensor(inputs).to(device)\n",
    "        labels = torch.Tensor(labels).max(1)[1].type(torch.LongTensor).to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i%20 == 19:\n",
    "            print('[%d] loss: %.3f' %(epoch + 1, running_loss / (20*BATCH_SIZE)))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "        optimizer.step()\n",
    "        \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(int(EMONEW.lenght(False)/BATCH_SIZE)):\n",
    "            inputs, labels = EMONEW.get_batch(BATCH_SIZE, False)\n",
    "            inputs = torch.Tensor(inputs).to(device)\n",
    "            outputs = net(inputs)\n",
    "            labels = torch.Tensor(labels).max(1)[1].type(torch.LongTensor).to(device)\n",
    "            test_loss += criterion(outputs, labels) # sum up batch loss\n",
    "            pred = outputs.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= EMONEW.lenght(False)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, EMONEW.lenght(False),\n",
    "        100. * correct / EMONEW.lenght(False)))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''del outputs\n",
    "del inputs\n",
    "del net\n",
    "torch.cuda.empty_cache()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.c0 = nn.Conv2d(3, 96, kernel_size=(5,5))\n",
    "        self.bn1 = nn.BatchNorm2d(96)\n",
    "        self.c1 = nn.Conv2d(96, 128, kernel_size=(3,3))\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.c2 = nn.Conv2d(128, 128, kernel_size=(3,3))\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.c3 = nn.Conv2d(128, 192, kernel_size=(3,3))\n",
    "        \n",
    "        self.fc1 = nn.Linear(192*15*14, 32)\n",
    "        self.fc2 = nn.Linear(32, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x/255\n",
    "        x = F.max_pool2d(F.relu(self.bn1(self.c0(x))), kernel_size=4)\n",
    "        x = F.max_pool2d(F.relu(F.dropout2d(self.bn2(self.c1(x)), inplace=True)), kernel_size=2)\n",
    "        x = F.max_pool2d(F.relu(F.dropout2d(self.bn3(self.c2(x)), inplace=True)), kernel_size=2)\n",
    "        x = F.relu(self.c3(x))\n",
    "        x = x.view(-1, 192*15*14)\n",
    "        x = F.relu(F.dropout(self.fc1(x), inplace=True))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv = ConvNet().to(device)\n",
    "print(conv)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(conv.parameters(), lr=0.1, momentum=0, weight_decay = 0.9999)\n",
    "EMONEW = DatasetLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "for epoch in range(250):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i in range(int(EMONEW.lenght()/BATCH_SIZE)):\n",
    "        conv.train()\n",
    "        # get the inputs\n",
    "        inputs, labels = EMONEW.get_batch(BATCH_SIZE)\n",
    "        inputs = torch.Tensor(inputs).to(device)\n",
    "        labels = torch.Tensor(labels).max(1)[1].type(torch.LongTensor).to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = conv(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i%20 == 19:\n",
    "            print('[%d] loss: %.3f' %(epoch + 1, running_loss / (20*BATCH_SIZE)))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i in range(int(EMONEW.lenght(False)/BATCH_SIZE)):\n",
    "            inputs, labels = EMONEW.get_batch(BATCH_SIZE, False)\n",
    "            inputs = torch.Tensor(inputs).to(device)\n",
    "            outputs = conv(inputs)\n",
    "            labels = torch.Tensor(labels).max(1)[1].type(torch.LongTensor).to(device)\n",
    "            test_loss += criterion(outputs, labels) # sum up batch loss\n",
    "            pred = outputs.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= EMONEW.lenght(False)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, EMONEW.lenght(False),\n",
    "        100. * correct / EMONEW.lenght(False)))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del outputs\n",
    "del inputs\n",
    "del conv\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
